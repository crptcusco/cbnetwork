# External imports
import itertools  # Provides functions for efficient looping and combination generation
import logging
import multiprocessing  # Library for parallel execution using multiple processes
import os
import random  # Library for generating random numbers and shuffling data
from itertools import \
    product  # Function to generate Cartesian product of input iterables
from math import \
    ceil  # Provides mathematical functions, including rounding up values
from multiprocessing import \
    Pool  # Class to manage parallel execution of a function across multiple processes
from typing import (  # Type hints for better code readability and type safety
    Any, Dict, List, Optional)

from dask import (  # Library for parallel computing using task scheduling with Dask
    compute, delayed)

from classes.cbnetwork_utils import _convert_to_tuple as _convert_to_tuple
from classes.cbnetwork_utils import \
    cartesian_product_mod as _cartesian_product_mod
from classes.cbnetwork_utils import evaluate_pair as _evaluate_pair
from classes.cbnetwork_utils import flatten as _flatten
from classes.cbnetwork_utils import \
    process_single_base_pair as _process_single_base_pair
from classes.directededge import DirectedEdge
# internal imports
from classes.globalscene import GlobalScene
from classes.globaltopology import GlobalTopology
from classes.internalvariable import InternalVariable
from classes.localnetwork import LocalNetwork
from classes.localscene import LocalAttractor
from classes.localtemplates import LocalNetworkTemplate
from classes.utils.customtext import CustomText
from classes.utils.logging_config import setup_logging

setup_logging()

logger = logging.getLogger(__name__)


class CBN:
    """
    Represents a Complex Boolean Network (CBN).

    A CBN consists of multiple interconnected local Boolean networks,
    where each network can have its own set of attractors and dynamic behavior.

    Attributes:
        l_local_networks (list[LocalNetwork]):
            A list of local Boolean networks within the CBN.
        l_directed_edges (list[DirectedEdge]):
            A list of directed edges representing the interactions between local networks.
        d_local_attractors (dict):
            A dictionary mapping local networks to their respective attractors.
        d_attractor_pair (dict):
            A dictionary storing compatible attractor pairs for network transitions.
        d_attractor_fields (dict):
            A dictionary representing attractor fields, which define stable attractor configurations.
        l_global_scenes (list[GlobalScene]):
            A list of global scenes, representing different global configurations of the CBN.
        d_global_scenes_count (dict):
            A dictionary keeping track of the number of occurrences of each global scene.
        o_global_topology (GlobalTopology or None):
            An object representing the global topology of the network, initially set to None.
    """

    def __init__(self, l_local_networks: list, l_directed_edges: list):
        """
        Initializes a Complex Boolean Network with a set of local networks and directed edges.

        Args:
            l_local_networks (list[LocalNetwork]):
                The list of local networks that form the CBN.
            l_directed_edges (list[DirectedEdge]):
                The list of directed edges defining connections between local networks.
        """
        # Stores the provided local networks and edges
        self.l_local_networks = l_local_networks
        self.l_directed_edges = l_directed_edges

        # Data structures for attractor and field calculations
        self.d_local_attractors = {}  # Stores attractors for each local network
        self.d_attractor_pair = {}  # Stores compatible attractor pairs
        self.d_attractor_fields = {}  # Stores attractor field mappings
        self.l_global_scenes = []  # Stores global network states
        self.d_global_scenes_count = {}  # Tracks frequency of global scenes

        # Placeholder for the global topology (to be initialized later)
        self.o_global_topology = None

    # PRINCIPAL FUNCTIONS
    def process_output_signals(self) -> None:
        """
        Update output signals for every local network based on directed edges.

        This method iterates over all local networks and directed edges,
        and appends each directed edge to the output signals of the local
        network if the local network's index matches the destination node
        of the directed edge.
        """
        # Create a dictionary for quick lookup of output signals
        local_network_dict = {
            network.l_index: network for network in self.l_local_networks
        }

        # Update output signals for each local network
        for edge in self.l_directed_edges:
            source, destination = edge
            if destination in local_network_dict:
                o_local_network = local_network_dict[destination]
                o_local_network.output_signals.append(edge)
                # print(edge)

    def update_network_by_index(self, o_local_network_update) -> bool:
        """
        Update a local network in the list by its index.

        Args:
            o_local_network_update (LocalNetwork): The local network object with updated information.

        Returns:
            bool: True if the network was found and updated, False otherwise.
        """
        # Iterate over the list of local networks
        for i, o_local_network in enumerate(self.l_local_networks):
            if o_local_network.index == o_local_network_update.index:
                # Update the local network in the list
                self.l_local_networks[i] = o_local_network_update
                # print(f"Local Network with index {o_local_network_update.index} updated")
                return True

        # If no network was found, print an error message
        # print(f"ERROR: Local Network with index {o_local_network_update.index} not found")
        return False

    @staticmethod
    def _generate_local_scenes(o_local_network: LocalNetwork) -> Optional[List[str]]:
        """
        Generate local scenes for the given local network based on external variables.

        Args:
            o_local_network (LocalNetwork): The local network object.

        Returns:
            Optional[List[str]]: A list of local scenes or None if there are no external variables.
        """
        external_vars_count = len(o_local_network.external_variables)
        if external_vars_count > 0:
            # Generate binary combinations for the external variables
            return [
                "".join(scene) for scene in product("01", repeat=external_vars_count)
            ]
        return None

    @staticmethod
    def process_local_network_mp(o_local_network):
        """
        Processes a local network to find its attractors.
        If an error occurs, an error message is printed, and the network is returned unchanged.

        Args:
            o_local_network: The local network object to be processed.

        Returns:
            The updated local network with its attractors found, or the original network if an error occurs.
        """
        try:
            # Generate local scenes from the given local network
            local_scenes = CBN._generate_local_scenes(o_local_network)

            # Find and update the local network's attractors
            updated_network = LocalNetwork.find_local_attractors(
                o_local_network=o_local_network, local_scenes=local_scenes
            )

            # Return the updated network
            return updated_network

        except Exception as e:
            logger = logging.getLogger(__name__)
            logger.exception(
                "Error processing network %s: %s",
                getattr(o_local_network, "id", "<unknown>"),
                e,
            )
            return o_local_network

    @staticmethod
    def process_output_signal_mp(args):
        """
        Processes an output signal to compute compatible attractor pairs.

        Args:
            args (tuple): Contains the following elements:
                - signal_index (int): Identifier of the signal.
                - l_attractors_input_0 (list): List of attractor indices for input value 0.
                - l_attractors_input_1 (list): List of attractor indices for input value 1.
                - index_variable (Any): The signal variable used to retrieve attractors.
                - get_attractors_func (Callable): Function to retrieve attractors,
                  typically self.get_attractors_by_input_signal_value.

        Returns:
            tuple: (signal_index, d_comp_pairs_attractors_by_value, n_pairs)
                - signal_index (int): The identifier of the processed signal.
                - d_comp_pairs_attractors_by_value (dict): Dictionary with keys {0,1},
                  where each value is a list of compatible attractor pairs.
                - n_pairs (int): The total number of attractor pairs found.
        """
        # Unpack input arguments
        (
            signal_index,
            l_attractors_input_0,
            l_attractors_input_1,
            index_variable,
            get_attractors_func,
        ) = args

        def find_attractor_pairs(
            signal_value: int, index_variable: Any, l_attractors_input: list
        ):
            """
            Finds compatible attractor pairs for a given signal value.

            Args:
                signal_value (int): The value of the signal (0 or 1).
                index_variable (Any): The variable used to retrieve attractors.
                l_attractors_input (list): List of input attractor indices.

            Returns:
                list: A list of compatible attractor pairs as tuples.
            """
            # Retrieve the output attractors corresponding to the given signal value
            l_attractors_output = [
                o_attractor.g_index
                for o_attractor in get_attractors_func(index_variable, signal_value)
            ]

            # Generate all possible pairs between input and output attractors
            return list(itertools.product(l_attractors_input, l_attractors_output))

        # Compute compatible pairs for both signal values (0 and 1)
        d_comp_pairs = {
            0: find_attractor_pairs(0, index_variable, l_attractors_input_0),
            1: find_attractor_pairs(1, index_variable, l_attractors_input_1),
        }

        # Count the total number of attractor pairs
        n_pairs = len(d_comp_pairs[0]) + len(d_comp_pairs[1])

        # Return the signal index, computed pairs, and the total count
        return signal_index, d_comp_pairs, n_pairs

    @staticmethod
    def evaluate_pair(
        base_pairs: list, candidate_pair: tuple, d_local_attractors
    ) -> bool:
        """
        Checks whether a candidate pair is compatible with the base pairs.

        The function recursively flattens each pair to extract individual indices and
        verifies whether the candidate pair maintains the compatibility conditions.

        Args:
            base_pairs (list): List of existing base pairs of attractors.
            candidate_pair (tuple): The new pair to evaluate.
            d_local_attractors (dict): A dictionary mapping attractor indices to their corresponding local networks.

        Returns:
            bool: True if the candidate pair is compatible, False otherwise.
        """

        def flatten(x):
            """
            Recursively flattens nested lists or tuples into a single sequence of elements.

            Args:
                x (Any): A nested list, tuple, or single element.

            Yields:
                Elements in a fully flattened form.
            """
            if isinstance(x, (list, tuple)):
                for item in x:
                    yield from flatten(item)  # Recursively flatten nested elements
            else:
                yield x  # Base case: yield individual elements

        # Flatten all base pairs to extract individual attractor indices.
        base_attractor_indices = {x for pair in base_pairs for x in flatten(pair)}

        # Extract the set of networks already visited based on base attractors.
        already_visited_networks = {
            d_local_attractors[idx][0] for idx in base_attractor_indices
        }

        double_check = 0
        # Flatten the candidate pair and check its compatibility.
        for candidate_idx in flatten(candidate_pair):
            if d_local_attractors[candidate_idx][0] in already_visited_networks:
                if candidate_idx in base_attractor_indices:
                    double_check += 1  # Candidate already exists in base pairs
            else:
                double_check += 1  # Candidate belongs to a new network

        # A valid pair must introduce exactly two new elements to the set
        return double_check == 2

    @staticmethod
    def cartesian_product_mod(
        base_pairs: list, candidate_pairs: list, d_local_attractors
    ) -> list:
        """
        Performs a modified Cartesian product between two lists of pairs, filtering out incompatible combinations.

        This function iterates through all possible combinations of `base_pairs` and `candidate_pairs`,
        checks their compatibility using `evaluate_pair`, and appends valid pairs to the result list.

        Args:
            base_pairs (list): A list of base attractor pairs.
            candidate_pairs (list): A list of new candidate attractor pairs.
            d_local_attractors (dict): A dictionary mapping attractor indices to their corresponding local networks.

        Returns:
            list: A list of new combined pairs that are considered compatible.
        """
        field_pair_list = (
            []
        )  # Stores the valid combinations of base and candidate pairs.

        for base_pair in base_pairs:
            for candidate_pair in candidate_pairs:
                # Convert base_pair to a list if it's a tuple to allow concatenation.
                if isinstance(base_pair, tuple):
                    base_pair = list(base_pair)

                # Check if the new pair is compatible before adding it.
                if CBN.evaluate_pair(base_pair, candidate_pair, d_local_attractors):
                    new_pair = base_pair + [
                        candidate_pair
                    ]  # Merge base and candidate pairs.
                    field_pair_list.append(new_pair)

        return field_pair_list

    @staticmethod
    def _convert_to_tuple(x):
        """
        Recursively converts lists into tuples to make them hashable.

        This function ensures that nested lists are transformed into immutable tuples,
        which allows them to be used as dictionary keys or stored in sets.

        Args:
            x (Any): A value that could be a list or any other data type.

        Returns:
            Any: A tuple if the input was a list, otherwise the original value.
        """
        if isinstance(x, list):
            return tuple(
                CBN._convert_to_tuple(item) for item in x
            )  # Recursively convert nested lists to tuples.
        return x  # Return unchanged if it's not a list.

    @staticmethod
    def process_single_base_pair(base_pair, candidate_pairs, d_local_attractors):
        """
        Processes a single base pair by applying `cartesian_product_mod` to generate new compatible pairs.

        This function wraps the `cartesian_product_mod` function, ensuring that the given
        base pair is processed individually by converting it into a single-element list.

        Args:
            base_pair (Any): A single base pair to be combined with candidate pairs.
            candidate_pairs (list): A list of candidate pairs to be tested for compatibility.
            d_local_attractors (dict): A dictionary mapping attractor indices to network information.

        Returns:
            list: A list of new pairs generated after applying the Cartesian product modification.
        """
        return CBN.cartesian_product_mod(
            [base_pair], candidate_pairs, d_local_attractors
        )

    def find_local_attractors_sequential(self, num_cpus: int = 2):
        """
        Finds local attractors sequentially and updates the list of local attractors in the object.

        This method calculates the local attractors for each local network, updates the coupling signals,
        assigns global indices to each attractor, and generates the attractor dictionary.
        """

        if num_cpus:
            os.environ["OMP_NUM_THREADS"] = str(num_cpus)
            os.environ["MKL_NUM_THREADS"] = str(num_cpus)

        CustomText.make_title("FIND LOCAL ATTRACTORS")

        for o_local_network in self.l_local_networks:
            # Generate the local network scenes
            local_scenes = CBN._generate_local_scenes(o_local_network)
            # Calculate the local attractors for the local network
            o_local_network = LocalNetwork.find_local_attractors(
                o_local_network=o_local_network, local_scenes=local_scenes
            )

        # Update the coupling signals to be analyzed
        for o_local_network in self.l_local_networks:
            self.process_kind_signal(o_local_network)

        # Assign global indices to each attractor
        self._assign_global_indices_to_attractors()

        # Generate the attractor dictionary
        self.generate_attractor_dictionary()

        logger = logging.getLogger(__name__)
        logger.info("Number of local attractors: %d", self._count_total_attractors())
        CustomText.make_sub_sub_title("END FIND LOCAL ATTRACTORS")

    def find_local_attractors_parallel(self, num_cpus=None):
        """
        Paraleliza el proceso de encontrar atractores locales utilizando multiprocessing.

        Para cada red local en self.l_local_networks se:
          1. Generan sus escenas locales.
          2. Se calculan sus atractores locales.

        Luego, en el proceso principal se actualiza cada red con su respectivo procesamiento
        de señales, se asignan los índices globales a cada atractor y se genera el diccionario de atractores.

        Esta función es equivalente a la versión secuencial, pero distribuye el cálculo de cada
        red local en procesos independientes.
        """
        CustomText.make_title("FIND LOCAL ATTRACTORS PARALLEL")

        if num_cpus is None or num_cpus <= 0:
            num_cpus = multiprocessing.cpu_count()

        # Crear un pool de procesos; se puede ajustar el número de procesos si es necesario
        with multiprocessing.Pool(processes=num_cpus) as pool:
            # map() enviará cada elemento de self.l_local_networks a la función process_local_network_mp
            updated_networks = pool.map(
                CBN.process_local_network_mp, self.l_local_networks
            )

        # Actualizar la lista de redes locales con los resultados obtenidos
        self.l_local_networks = list(updated_networks)

        # Asignar índices globales a cada atractor
        self._assign_global_indices_to_attractors()

        # Generar el diccionario de atractores
        self.generate_attractor_dictionary()

        CustomText.make_sub_sub_title("END FIND LOCAL ATTRACTORS PARALLEL")

    def find_local_attractors_parallel_with_weigths(self, num_cpus=None):
        """
        Encuentra atractores locales en paralelo con multiprocessing, balanceando la carga
        mediante un sistema de 'buckets' según el peso de cada tarea.
        """
        CustomText.make_title("FIND LOCAL ATTRACTORS WEIGHTED BALANCED")

        if num_cpus is None or num_cpus <= 0:
            num_cpus = multiprocessing.cpu_count()

        # Crear lista de tareas con peso
        tasks_with_weight = []
        for o_local_network in self.l_local_networks:
            num_vars = (
                len(o_local_network.total_variables)
                if hasattr(o_local_network, "total_variables")
                else 0
            )
            num_coupling = (
                len(o_local_network.input_signals)
                if hasattr(o_local_network, "input_signals")
                else 0
            )
            weight = num_vars * (2**num_coupling)
            tasks_with_weight.append((weight, o_local_network))

        # Ordenar por peso descendente
        tasks_with_weight.sort(key=lambda x: x[0], reverse=True)

        # Crear buckets balanceados
        buckets = [{"total": 0, "tasks": []} for _ in range(num_cpus)]
        for weight, task in tasks_with_weight:
            bucket = min(buckets, key=lambda b: b["total"])
            bucket["tasks"].append(task)
            bucket["total"] += weight

        # Imprimir info inicial
        logger = logging.getLogger(__name__)
        logger.info("Número de workers: %d", num_cpus)
        logger.info("Distribución de tareas por bucket antes de la ejecución:")
        for i, bucket in enumerate(buckets):
            logger.info(
                "  Bucket %d: %d tasks, total weight: %d",
                i,
                len(bucket["tasks"]),
                bucket["total"],
            )

        # Ejecutar en paralelo con multiprocessing
        all_tasks = [task for bucket in buckets for task in bucket["tasks"]]
        with Pool(processes=num_cpus) as pool:
            results = pool.map(CBN.process_local_network_mp, all_tasks)

        # Verificar si alguna red desapareció
        if len(results) != len(self.l_local_networks):
            logger.warning(
                "Se perdieron %d redes en el proceso!",
                len(self.l_local_networks) - len(results),
            )

        # Emparejar redes originales con los resultados usando índices
        ordered_results = [None] * len(self.l_local_networks)
        for original, processed in zip(all_tasks, results):
            index = self.l_local_networks.index(original)  # Buscar la posición original
            ordered_results[index] = processed

        # Verificar si hubo algún None (indica error en la asignación)
        if None in ordered_results:
            logger.warning("Algunos resultados no se reasignaron correctamente!")

        self.l_local_networks = ordered_results  # Asignar en el orden correcto

        # Procesar señales por red local
        for o_local_network in self.l_local_networks:
            self.process_kind_signal(o_local_network)

        # Asignar índices globales a los attratores
        self._assign_global_indices_to_attractors()
        # Generar el diccionario de attractores
        self.generate_attractor_dictionary()

        # Imprimir info final de los buckets
        logger.info("Información final de los buckets:")
        for i, bucket in enumerate(buckets):
            logger.info(
                "  Bucket %d: %d tasks, total weight: %d",
                i,
                len(bucket["tasks"]),
                bucket["total"],
            )

        CustomText.make_sub_sub_title("END FIND LOCAL ATTRACTORS WEIGHTED BALANCED")

    def _assign_global_indices_to_attractors(self) -> None:
        """
        Assign global indices to each attractor in all local networks.
        """
        i_attractor = 1
        for o_local_network in self.l_local_networks:
            for o_local_scene in o_local_network.local_scenes:
                for o_attractor in o_local_scene.l_attractors:
                    o_attractor.g_index = i_attractor
                    i_attractor += 1

    def generate_attractor_dictionary(self) -> None:
        """
        Generates a Dictionary of local attractors
        :return: a list of triples (a,b,c) where:
         - 'a' is the network index
         - 'b' is the scene index
         - 'c' is the local attractor index
        """
        d_local_attractors = {}
        for o_local_network in self.l_local_networks:
            for o_scene in o_local_network.local_scenes:
                for o_attractor in o_scene.l_attractors:
                    t_triple = (
                        o_local_network.index,
                        o_scene.index,
                        o_attractor.l_index,
                    )
                    d_local_attractors[o_attractor.g_index] = t_triple

        self.d_local_attractors = d_local_attractors

    def process_kind_signal(self, o_local_network: LocalNetwork) -> None:
        """
        Update the coupling signals to be analyzed for the given local network.

        Args:
            o_local_network (LocalNetwork): The local network object.
        """

        def get_true_table_index(o_state, o_output_signal):
            true_table_index = ""
            for v_output_variable in o_output_signal.l_output_variables:
                pos = o_local_network.total_variables.index(v_output_variable)
                value = o_state.l_variable_values[pos]
                true_table_index += str(value)
            return true_table_index

        def update_output_signals(l_signals_in_attractor, o_output_signal, o_attractor):
            output_value = l_signals_in_attractor[0]
            if output_value == "0":
                o_output_signal.d_out_value_to_attractor[0].append(o_attractor)
            elif output_value == "1":
                o_output_signal.d_out_value_to_attractor[1].append(o_attractor)

        l_directed_edges = CBN.find_output_edges_by_network_index(
            o_local_network.index, self.l_directed_edges
        )

        for o_output_signal in l_directed_edges:
            l_signals_for_output = []
            for o_local_scene in o_local_network.local_scenes:
                l_signals_in_local_scene = []
                for o_attractor in o_local_scene.l_attractors:
                    l_signals_in_attractor = [
                        o_output_signal.true_table[
                            get_true_table_index(o_state, o_output_signal)
                        ]
                        for o_state in o_attractor.l_states
                    ]

                    if len(set(l_signals_in_attractor)) == 1:
                        l_signals_in_local_scene.append(l_signals_in_attractor[0])
                        update_output_signals(
                            l_signals_in_attractor, o_output_signal, o_attractor
                        )

                if len(set(l_signals_in_local_scene)) == 1:
                    l_signals_for_output.append(l_signals_in_local_scene[0])
                else:
                    l_signals_for_output.extend(l_signals_in_local_scene)

            signal_set_length = len(set(l_signals_for_output))
            if signal_set_length == 1:
                o_output_signal.kind_signal = 1
                # print("INFO: the output signal is restricted")
            elif signal_set_length == 2:
                o_output_signal.kind_signal = 3
                # print("INFO: the output signal is stable")
            else:
                o_output_signal.kind_signal = 4
                # print("INFO: the scene signal is not stable. This CBN doesn't have stable Attractor Fields")

    def _count_total_attractors(self) -> int:
        """
        Count the total number of attractors across all local networks.

        Returns:
            int: The total number of attractors.
        """
        return sum(
            len(o_local_scene.l_attractors)
            for o_local_network in self.l_local_networks
            for o_local_scene in o_local_network.local_scenes
        )

    def find_compatible_pairs(self, num_cpus: int = 2) -> None:
        """
        Generate pairs of attractors using the output signal.

        Returns:
            None: Updates the dictionary of compatible attractor pairs in the object.
        """

        if num_cpus:
            os.environ["OMP_NUM_THREADS"] = str(num_cpus)
            os.environ["MKL_NUM_THREADS"] = str(num_cpus)

        CustomText.make_title("FIND COMPATIBLE ATTRACTOR PAIRS")

        # Procesar señales de acoplamiento para cada red local
        for o_local_network in self.l_local_networks:
            self.process_kind_signal(o_local_network)

        def find_attractor_pairs(signal_value, o_output_signal, l_attractors_input):
            """
            Find pairs of attractors based on the input signal value.

            Args:
                signal_value (int): The signal value (0 or 1).
                o_output_signal: The output signal object.
                l_attractors_input (list): List of attractor indices for the input signal.

            Returns:
                list: List of unique pairs of attractors.
            """
            l_attractors_output = [
                o_attractor.g_index
                for o_attractor in self.get_attractors_by_input_signal_value(
                    o_output_signal.index_variable, signal_value
                )
            ]

            # Usamos un conjunto para evitar pares duplicados
            unique_pairs = set(
                itertools.product(l_attractors_input, l_attractors_output)
            )

            return list(unique_pairs)

        n_pairs = 0

        for o_local_network in self.l_local_networks:
            l_output_edges = self.get_output_edges_by_network_index(
                o_local_network.index
            )

            for o_output_signal in l_output_edges:
                l_attractors_input_0 = list(
                    set(
                        attr.g_index
                        for attr in o_output_signal.d_out_value_to_attractor[0]
                    )
                )
                l_attractors_input_1 = list(
                    set(
                        attr.g_index
                        for attr in o_output_signal.d_out_value_to_attractor[1]
                    )
                )

                o_output_signal.d_comp_pairs_attractors_by_value[0] = (
                    find_attractor_pairs(0, o_output_signal, l_attractors_input_0)
                )
                o_output_signal.d_comp_pairs_attractors_by_value[1] = (
                    find_attractor_pairs(1, o_output_signal, l_attractors_input_1)
                )

                n_pairs += len(o_output_signal.d_comp_pairs_attractors_by_value[0])
                n_pairs += len(o_output_signal.d_comp_pairs_attractors_by_value[1])

        logger = logging.getLogger(__name__)
        logger.info("END FIND ATTRACTOR PAIRS (Total pairs: %d)", n_pairs)

    def find_compatible_pairs_parallel(self, num_cpus=None):
        """
        Paraleliza la generación de pares compatibles utilizando multiprocessing,
        procesando cada señal de salida en un proceso independiente.

        Para cada red local, se obtienen sus output edges y, para cada señal de salida:
          - Se extraen las listas de atractores de entrada (para 0 y 1).
          - Se procesa la señal para calcular los pares compatibles mediante la función auxiliar.

        Al finalizar, se actualizan los objetos de señal con los diccionarios de pares y se
        imprime el total de pares encontrados.

        Actualiza el estado interno del objeto (self.l_local_networks) con las señales modificadas.
        """
        CustomText.make_title("FIND COMPATIBLE ATTRACTOR PAIRS (PARALLEL)")

        # Procesar señales de acoplamiento para cada red local
        for o_local_network in self.l_local_networks:
            self.process_kind_signal(o_local_network)

        if num_cpus is None or num_cpus <= 0:
            num_cpus = multiprocessing.cpu_count()

        tasks = []
        signal_map = {}
        # Recorrer todas las redes locales
        for o_local_network in self.l_local_networks:
            l_output_edges = self.get_output_edges_by_network_index(
                o_local_network.index
            )
            # Procesar cada output signal
            for o_output_signal in l_output_edges:
                signal_index = o_output_signal.index
                signal_map[signal_index] = (
                    o_output_signal  # Guardar referencia para actualizar luego
                )
                l_attractors_input_0 = [
                    attr.g_index for attr in o_output_signal.d_out_value_to_attractor[0]
                ]
                l_attractors_input_1 = [
                    attr.g_index for attr in o_output_signal.d_out_value_to_attractor[1]
                ]
                task_args = (
                    signal_index,
                    l_attractors_input_0,
                    l_attractors_input_1,
                    o_output_signal.index_variable,
                    self.get_attractors_by_input_signal_value,
                )
                tasks.append(task_args)

        logging.getLogger(__name__).info("Tareas creadas: %d", len(tasks))

        # Ejecutar las tareas en paralelo
        with Pool(processes=num_cpus) as pool:
            results = pool.map(CBN.process_output_signal_mp, tasks)

        logging.getLogger(__name__).info("Resultados obtenidos: %d", len(results))
        total_pairs = 0
        # Actualizar los objetos de salida con los resultados obtenidos
        for signal_index, d_comp_pairs, n_signal_pairs in results:
            if signal_index not in signal_map:
                logger.error(
                    "Índice de señal %s no encontrado en signal_map", signal_index
                )
                continue
            o_output_signal = signal_map[signal_index]
            o_output_signal.d_comp_pairs_attractors_by_value = d_comp_pairs
            total_pairs += n_signal_pairs

        CustomText.make_sub_sub_title(
            f"END FIND COMPATIBLE ATTRACTOR PAIRS (Total pairs: {total_pairs})"
        )

    def find_compatible_pairs_parallel_with_weights(self, num_cpus=None):
        """
        Parallelizes the generation of compatible pairs using multiprocessing,
        assigning tasks (each corresponding to a coupling signal) to weight-balanced buckets.
        The weight of each task is calculated as:

             weight = len(l_attractors_input_0) + len(l_attractors_input_1)

        Then, all tasks are executed in parallel, and the original objects are updated.
        """
        CustomText.make_title("FIND COMPATIBLE ATTRACTOR PAIRS (PARALLEL WITH WEIGHTS)")

        # Process coupling signals for each local network
        for local_network in self.l_local_networks:
            self.process_kind_signal(local_network)

        if num_cpus is None or num_cpus <= 0:
            num_cpus = multiprocessing.cpu_count()

        tasks_with_weight = []
        signal_map = {}

        # Iterate over each local network and its output signals
        for local_network in self.l_local_networks:
            output_edges = self.get_output_edges_by_network_index(local_network.index)
            for output_signal in output_edges:

                # Get the number of attractors in the input network
                input_network = self.get_network_by_index(
                    output_signal.input_local_network
                )
                n_local_attractors = input_network.attractor_count

                signal_index = output_signal.index
                # Save the reference for later update
                signal_map[signal_index] = output_signal
                l_attractors_input_0 = [
                    attr.g_index for attr in output_signal.d_out_value_to_attractor[0]
                ]
                l_attractors_input_1 = [
                    attr.g_index for attr in output_signal.d_out_value_to_attractor[1]
                ]
                # Define the task's weight (you can adjust this formula if needed)
                weight = (
                    len(l_attractors_input_0) + len(l_attractors_input_1)
                ) * n_local_attractors
                task_args = (
                    signal_index,
                    l_attractors_input_0,
                    l_attractors_input_1,
                    output_signal.index_variable,
                    self.get_attractors_by_input_signal_value,
                )
                tasks_with_weight.append((weight, task_args))

        # Sort the tasks by weight, from highest to lowest
        tasks_with_weight.sort(key=lambda x: x[0], reverse=True)

        # Create buckets to balance the load across the CPUs
        buckets = [{"total": 0, "tasks": []} for _ in range(num_cpus)]
        for weight, task in tasks_with_weight:
            bucket = min(buckets, key=lambda b: b["total"])
            bucket["tasks"].append(task)
            bucket["total"] += weight

        # Print bucket information before execution
        logger = logging.getLogger(__name__)
        logger.info("Number of CPUs: %d", num_cpus)
        logger.info("Task distribution by bucket before execution:")
        for i, bucket in enumerate(buckets):
            logger.info(
                "  Bucket %d: %d tasks, total weight: %d",
                i,
                len(bucket["tasks"]),
                bucket["total"],
            )

        # Combine all tasks into a single list for parallel execution
        all_tasks = []
        for bucket in buckets:
            all_tasks.extend(bucket["tasks"])

        # Execute all tasks in parallel using multiprocessing
        with Pool(processes=num_cpus) as pool:
            results = pool.map(CBN.process_output_signal_mp, all_tasks)

        logging.getLogger(__name__).info("Number of tasks processed: %d", len(results))

        total_pairs = 0
        # Update output signal objects with the obtained results
        for signal_index, d_comp_pairs, n_signal_pairs in results:
            if signal_index not in signal_map:
                logging.getLogger(__name__).error(
                    "Error: Signal index %s not found in signal_map", signal_index
                )
                continue
            output_signal = signal_map[signal_index]

            # Remove duplicates from the compatible pairs dictionary.
            # d_comp_pairs is expected to be a dictionary with keys 0 and 1.
            unique_pairs_dict = {}
            new_n_signal_pairs = 0
            for key, pair_list in d_comp_pairs.items():
                unique_set = set()
                for pair in pair_list:
                    # Convert each pair to a tuple to ensure hashability
                    unique_set.add(tuple(pair))
                unique_pairs_list = list(unique_set)
                unique_pairs_dict[key] = unique_pairs_list
                new_n_signal_pairs += len(unique_pairs_list)

            output_signal.d_comp_pairs_attractors_by_value = unique_pairs_dict
            total_pairs += new_n_signal_pairs

        logging.getLogger(__name__).info(
            "END FIND COMPATIBLE ATTRACTOR PAIRS (Total unique pairs: %d)", total_pairs
        )

    def order_edges_by_compatibility(self):
        """
        Order the directed edges based on their compatibility.

        The compatibility is determined if the input or output local network of one edge
        matches with the input or output local network of any edge in the base group.
        """

        def is_compatible(l_group_base, o_group):
            """
            Check if the given edge group is compatible with any edge in the base group.

            Args:
                l_group_base (list): List of base edge groups.
                o_group: Edge group to be checked for compatibility.

            Returns:
                bool: True if compatible, False otherwise.
            """
            for aux_par in l_group_base:
                if (
                    aux_par.input_local_network == o_group.input_local_network
                    or aux_par.input_local_network == o_group.output_local_network
                ):
                    return True
                elif (
                    aux_par.output_local_network == o_group.output_local_network
                    or aux_par.output_local_network == o_group.input_local_network
                ):
                    return True
            return False

        # Initialize the base list with the first edge group
        l_base = [self.l_directed_edges[0]]
        aux_l_rest_groups = self.l_directed_edges[1:]

        # Process each remaining edge group
        for v_group in aux_l_rest_groups:
            if is_compatible(l_base, v_group):
                l_base.append(v_group)
            else:
                # If not compatible, move it to the end of the list
                aux_l_rest_groups.remove(v_group)
                aux_l_rest_groups.append(v_group)

        # Combine the base list with the rest of the groups
        self.l_directed_edges = [self.l_directed_edges[0]] + aux_l_rest_groups
        # print("Directed Edges ordered.")

    def order_edges_by_grade(self):
        """
        Orders the directed edges based on the total degree of the networks they connect.

        The total degree of an edge is the sum of the degrees of its input and output networks.
        The edges are then reordered to keep adjacent edges (sharing networks) close together.
        """

        # Paso 1: Calcular el grado de cada red local
        network_degrees = {net.index: 0 for net in self.l_local_networks}

        for edge in self.l_directed_edges:
            network_degrees[edge.input_local_network] += 1
            network_degrees[edge.output_local_network] += 1

        # Paso 2: Calcular el "grado total" de cada arista
        def calculate_edge_grade(edge):
            input_degree = network_degrees.get(edge.input_local_network, 0)
            output_degree = network_degrees.get(edge.output_local_network, 0)
            return input_degree + output_degree

        # Paso 3: Ordenar aristas por el grado total en orden descendente
        self.l_directed_edges.sort(key=calculate_edge_grade, reverse=True)

        # Paso 4: Reordenar para mantener aristas adyacentes juntas
        def is_adjacent(edge1, edge2):
            return (
                edge1.input_local_network == edge2.input_local_network
                or edge1.input_local_network == edge2.output_local_network
                or edge1.output_local_network == edge2.input_local_network
                or edge1.output_local_network == edge2.output_local_network
            )

        ordered_edges = [
            self.l_directed_edges.pop(0)
        ]  # Comenzamos con la arista de mayor grado

        while self.l_directed_edges:
            for i, edge in enumerate(self.l_directed_edges):
                if is_adjacent(ordered_edges[-1], edge):
                    ordered_edges.append(self.l_directed_edges.pop(i))
                    break
            else:
                # Si no encontramos adyacente, agregamos la siguiente disponible
                ordered_edges.append(self.l_directed_edges.pop(0))

        # Paso 5: Actualizar la lista de aristas
        self.l_directed_edges = ordered_edges

    def disorder_edges(self):
        """
        Desordena aleatoriamente la lista de aristas dirigidas, asegurando que la primera
        arista no tenga vértices en común con la segunda, y reasigna las aristas en la estructura.
        """
        if len(self.l_directed_edges) < 2:
            return  # No hay suficiente número de aristas para aplicar la condición

        # Mezclar aleatoriamente las aristas
        random.shuffle(self.l_directed_edges)

        # Verificar si la primera y la segunda comparten algún vértice
        def have_common_vertex(edge1, edge2):
            return edge1.input_local_network in {
                edge2.input_local_network,
                edge2.output_local_network,
            } or edge1.output_local_network in {
                edge2.input_local_network,
                edge2.output_local_network,
            }

        # Si la primera y segunda arista tienen un vértice en común, buscar una nueva segunda arista
        if have_common_vertex(self.l_directed_edges[0], self.l_directed_edges[1]):
            for i in range(2, len(self.l_directed_edges)):
                if not have_common_vertex(
                    self.l_directed_edges[0], self.l_directed_edges[i]
                ):
                    # Intercambiar la segunda arista con una que no comparta vértices
                    self.l_directed_edges[1], self.l_directed_edges[i] = (
                        self.l_directed_edges[i],
                        self.l_directed_edges[1],
                    )
                    break

    def mount_stable_attractor_fields(self, n_cpus: int = 2) -> None:
        """
        Assembles compatible attractor fields.

        This function assembles fields of attractors that are compatible with each other.
        """

        def evaluate_pair(base_pairs: list, candidate_pair: tuple) -> bool:
            """
            Checks if a candidate attractor pair is compatible with a base attractor pair.

            Args:
                base_pairs (list): List of base attractor pairs.
                candidate_pair (tuple): Candidate attractor pair.

            Returns:
                bool: True if the candidate pair is compatible with the base pairs, False otherwise.
            """

            # Extract the indices of local networks from each attractor pair
            base_attractor_indices = {
                attractor for pair in base_pairs for attractor in pair
            }

            # Generate the list of already visited networks
            already_visited_networks = {
                self.d_local_attractors[idx][0] for idx in base_attractor_indices
            }

            double_check = 0
            for candidate_idx in candidate_pair:
                if (
                    self.d_local_attractors[candidate_idx][0]
                    in already_visited_networks
                ):
                    if candidate_idx in base_attractor_indices:
                        double_check += 1
                else:
                    double_check += 1

            return double_check == 2

        def cartesian_product_mod(base_pairs: list, candidate_pairs: list) -> list:
            """
            Performs the modified Cartesian product of the attractor pairs lists.

            Args:
                base_pairs (list): List of base attractor pairs.
                candidate_pairs (list): List of candidate attractor pairs.

            Returns:
                list: List of candidate attractor fields.
            """
            field_pair_list = []

            for base_pair in base_pairs:
                for candidate_pair in candidate_pairs:
                    if isinstance(base_pair, tuple):
                        base_pair = [base_pair]
                    if evaluate_pair(base_pair, candidate_pair):
                        new_pair = base_pair + [candidate_pair]
                        field_pair_list.append(new_pair)

            return field_pair_list

        CustomText.make_title("FIND ATTRACTOR FIELDS")

        # Order the edges by compatibility
        self.order_edges_by_compatibility()

        # Generate the base list of pairs made with 0 or 1 coupling signal
        l_base_pairs = set(
            self.l_directed_edges[0].d_comp_pairs_attractors_by_value[0]
            + self.l_directed_edges[0].d_comp_pairs_attractors_by_value[1]
        )

        # Iterate over each edge to form unions with the base
        for o_directed_edge in self.l_directed_edges[1:]:
            l_candidate_pairs = (
                o_directed_edge.d_comp_pairs_attractors_by_value[0]
                + o_directed_edge.d_comp_pairs_attractors_by_value[1]
            )
            l_base_pairs = cartesian_product_mod(l_base_pairs, l_candidate_pairs)

            if not l_base_pairs:
                break

        # Generate a dictionary of attractor fields
        self.d_attractor_fields = {}
        for i, base_element in enumerate(l_base_pairs, start=1):
            self.d_attractor_fields[i] = list(
                {item for pair in base_element for item in pair}
            )

        # print("Number of attractor fields found:", len(l_base_pairs))
        CustomText.make_sub_sub_title("END MOUNT ATTRACTOR FIELDS")

    def mount_stable_attractor_fields_parallel(self, num_cpus=None):
        """Assemble stable attractor fields in parallel using multiprocessing.

        Process overview:
        1. Order edges by compatibility.
        2. Generate initial base pairs from the first edge.
        3. For each remaining edge, process base pairs in parallel and update the base.
        4. Build attractor fields from the final base and store them in
           ``self.d_attractor_fields``.
        """

        if num_cpus:
            os.environ["OMP_NUM_THREADS"] = str(num_cpus)
            os.environ["MKL_NUM_THREADS"] = str(num_cpus)

        CustomText.make_title("MOUNT STABLE ATTRACTOR FIELDS (PARALLEL)")

        if num_cpus is None or num_cpus <= 0:
            num_cpus = multiprocessing.cpu_count()

        # Paso 1: Ordenar las aristas por compatibilidad
        self.order_edges_by_compatibility()

        # Paso 2: Generar la base inicial de pares a partir de la primera arista
        base0 = self.l_directed_edges[0].d_comp_pairs_attractors_by_value[0]
        base1 = self.l_directed_edges[0].d_comp_pairs_attractors_by_value[1]
        l_base_pairs = set(base0 + base1)

        # Paso 3: Iterar sobre las aristas restantes para refinar la base de pares
        for o_directed_edge in self.l_directed_edges[1:]:
            l_candidate_pairs = (
                o_directed_edge.d_comp_pairs_attractors_by_value[0]
                + o_directed_edge.d_comp_pairs_attractors_by_value[1]
            )
            logger.info(
                "Procesando arista %s con %d pares base",
                o_directed_edge.index,
                len(l_base_pairs),
            )

            base_pairs_list = list(l_base_pairs)
            tasks_args = [
                (bp, l_candidate_pairs, self.d_local_attractors)
                for bp in base_pairs_list
            ]

            with Pool(processes=num_cpus) as pool:
                results = pool.starmap(CBN.process_single_base_pair, tasks_args)

            new_base_pairs = set()
            for r in results:
                for item in r:
                    if isinstance(item, list):
                        new_base_pairs.add(tuple(item))
                    else:
                        new_base_pairs.add(item)
            l_base_pairs = new_base_pairs

            logger.info("Base actualizada: %d pares", len(l_base_pairs))
            if not l_base_pairs:
                break

        # Paso 4: Generar el diccionario de campos de atractores a partir de la base final
        self.d_attractor_fields = {}
        for i, base_element in enumerate(l_base_pairs, start=1):
            field = set()
            try:
                for pair in base_element:
                    try:
                        for item in pair:
                            field.add(tuple(item) if isinstance(item, list) else item)
                    except TypeError:
                        field.add(pair)
            except TypeError:
                field.add(base_element)
            self.d_attractor_fields[i] = list(field)

        CustomText.make_sub_sub_title("END MOUNT STABLE ATTRACTOR FIELDS (PARALLEL)")

    @staticmethod
    def flatten(x):
        """
        Recursively flattens a nested list or tuple into a single sequence.
        """
        if isinstance(x, (list, tuple)):
            for item in x:
                yield from CBN.flatten(item)
        else:
            yield x

    def mount_stable_attractor_fields_parallel_chunks(self, num_cpus=None):
        """
        Assembles stable attractor fields in parallel using multiprocessing.

        The process is:
          1. Order the edges by compatibility.
          2. Generate the initial base pairs from the first edge.
          3. For each remaining edge:
               - Extract the candidate pairs for the current output signal.
               - Divide the current base into uniform chunks (based on num_cpus).
               - Process each chunk in parallel using cartesian_product_mod,
                 passing the candidate list and the d_local_attractors dictionary.
               - Merge the results (via set union) to update the base pairs.
          4. Finally, generate the attractor fields dictionary from the final base.

        Updates self.d_attractor_fields with the found fields.
        """
        CustomText.make_title("MOUNT STABLE ATTRACTOR FIELDS (PARALLEL CHUNKS)")

        if num_cpus is None or num_cpus <= 0:
            num_cpus = multiprocessing.cpu_count()

        # Step 1: Order the edges by compatibility
        self.order_edges_by_compatibility()

        # Step 2: Generate the initial base pairs from the first edge
        initial_pairs = (
            self.l_directed_edges[0].d_comp_pairs_attractors_by_value[0]
            + self.l_directed_edges[0].d_comp_pairs_attractors_by_value[1]
        )
        # Convert each element to a tuple, encapsulating if necessary
        l_base_pairs = set(
            tuple(item) if isinstance(item, (list, tuple)) else (item,)
            for item in initial_pairs
        )

        # Step 3: Iterate over the remaining edges to refine the base pairs
        for directed_edge in self.l_directed_edges[1:]:
            # Extract the candidate pairs for the current output signal
            candidate_pairs = (
                directed_edge.d_comp_pairs_attractors_by_value[0]
                + directed_edge.d_comp_pairs_attractors_by_value[1]
            )

            # Divide the current base into uniform chunks
            l_base_pairs_list = list(l_base_pairs)
            n = len(l_base_pairs_list)
            if n == 0:
                break
            chunk_size = ceil(n / num_cpus)
            chunks = [
                l_base_pairs_list[i:i + chunk_size] for i in range(0, n, chunk_size)
            ]

            logger.info(
                "Processing edge %s with %d base pairs; chunk size: %d",
                directed_edge.index,
                n,
                chunk_size,
            )
            for i, chunk in enumerate(chunks):
                logger.info("  Chunk %d: %d pairs", i, len(chunk))

            # Execute in parallel: for each chunk, call cartesian_product_mod
            with Pool(processes=num_cpus) as pool:
                args = [
                    (chunk, candidate_pairs, self.d_local_attractors)
                    for chunk in chunks
                ]
                iter_results = pool.starmap(CBN.cartesian_product_mod, args)

            # Merge the results: each result may be a list of new pairs
            new_base_pairs = set()
            for result in iter_results:
                if isinstance(result, list):
                    for item in result:
                        if isinstance(item, (list, tuple)):
                            new_base_pairs.add(tuple(item))
                        else:
                            new_base_pairs.add((item,))
                elif isinstance(result, (list, tuple)):
                    new_base_pairs.add(tuple(result))
                else:
                    new_base_pairs.add((result,))

            # Update the base pairs for the next iteration
            l_base_pairs = new_base_pairs
            logger.info("Updated base: %d pairs", len(l_base_pairs))
            if not l_base_pairs:
                break

        # Step 4: Generate the dictionary of attractor fields from the final base
        self.d_attractor_fields = {}
        for i, base_element in enumerate(l_base_pairs, start=1):
            # Flatten the base element to obtain a flat list of attractor indices
            flat_field = list(CBN.flatten(base_element))
            # Remove duplicates while preserving order
            seen = set()
            unique_flat_field = []
            for item in flat_field:
                if item not in seen:
                    seen.add(item)
                    unique_flat_field.append(item)
            self.d_attractor_fields[i] = unique_flat_field

        CustomText.make_sub_sub_title(
            f"END MOUNT STABLE ATTRACTOR FIELDS (Total:{len(l_base_pairs)})"
        )

    # DASK FUNCTIONS
    def dask_find_local_attractors(self):
        """
        Paraleliza el proceso de encontrar atractores locales utilizando Dask.

        Esta función divide el cálculo de atractores locales en subtareas paralelas y luego combina los resultados.
        """
        CustomText.make_title("FIND LOCAL ATTRACTORS")

        # Paso 1: Crear tareas paralelas para encontrar atractores locales
        def process_local_network(o_local_network):
            """
            Procesa una red local: genera escenas locales, encuentra atractores, y procesa señales.
            """
            # Generar escenas locales
            local_scenes = CBN._generate_local_scenes(o_local_network)

            # Encontrar atractores locales
            updated_network = LocalNetwork.find_local_attractors(
                o_local_network=o_local_network, local_scenes=local_scenes
            )

            return updated_network

        # Crear una lista de tareas usando dask.delayed
        delayed_tasks = [
            delayed(process_local_network)(o_local_network)
            for o_local_network in self.l_local_networks
        ]

        # Ejecutar todas las tareas en paralelo
        updated_networks = compute(*delayed_tasks)

        # Actualizar las redes locales con los resultados
        self.l_local_networks = list(
            updated_networks
        )  # Convertimos la tupla a lista para mantener el formato original

        # Procesar señales de acoplamiento
        for o_local_network in self.l_local_networks:
            self.process_kind_signal(o_local_network)

        # Paso 2: Asignar índices globales a cada atractor
        self._assign_global_indices_to_attractors()

        # Paso 3: Generar el diccionario de atractores
        self.generate_attractor_dictionary()

        CustomText.make_sub_sub_title("END FIND LOCAL ATTRACTORS")

    def dask_find_local_attractors_weighted_balanced(self, num_workers):
        """
        Paraleliza el proceso de encontrar atractores locales utilizando Dask,
        alocando las tareas según un peso definido como:

             peso = (cantidad de variables) * 2^(número de señales de acoplamiento)

        Luego, las tareas se agrupan en 'num_workers' buckets de forma que el peso
        total de cada bucket sea lo más equilibrado posible. Finalmente, se programan
        todas las tareas al mismo tiempo para que se ejecuten concurrentemente, y se
        actualiza la estructura del CBN.
        """
        CustomText.make_title("FIND LOCAL ATTRACTORS WEIGHTED BALANCED")

        # Función que se ejecutará para cada red local
        def process_local_network(o_local_network):
            # Genera las escenas locales usando el método (o función) estático de CBN
            local_scenes = CBN._generate_local_scenes(o_local_network)
            # Encuentra los atractores locales para la red (se asume que este método actualiza internamente el objeto)
            updated_network = LocalNetwork.find_local_attractors(
                o_local_network=o_local_network, local_scenes=local_scenes
            )
            return updated_network

        # Crear una lista de tareas junto con su peso
        tasks_with_weight = []
        for o_local_network in self.l_local_networks:
            # Se asume que cada red local tiene:
            #  - total_variables: lista de variables (internas/externas/totales)
            #  - input_signals: lista de señales de acoplamiento (o atributo similar)
            num_vars = (
                len(o_local_network.total_variables)
                if hasattr(o_local_network, "total_variables")
                else 0
            )
            num_coupling = (
                len(o_local_network.input_signals)
                if hasattr(o_local_network, "input_signals")
                else 0
            )
            weight = num_vars * (2**num_coupling)
            delayed_task = delayed(process_local_network)(o_local_network)
            tasks_with_weight.append((weight, delayed_task))

        # Ordenar las tareas por peso en orden descendente
        tasks_with_weight.sort(key=lambda x: x[0], reverse=True)

        # Crear buckets (grupos) para cada worker, para balancear la carga
        buckets = [{"total": 0, "tasks": []} for _ in range(num_workers)]
        for weight, task in tasks_with_weight:
            # Asignar la tarea al bucket con menor peso acumulado
            bucket = min(buckets, key=lambda b: b["total"])
            bucket["tasks"].append(task)
            bucket["total"] += weight

        # Para depuración, imprimir los pesos acumulados de cada bucket
        for i, bucket in enumerate(buckets):
            logger.info(
                "Bucket %d total weight: %d with %d tasks",
                i,
                bucket["total"],
                len(bucket["tasks"]),
            )

        # En lugar de computar cada bucket secuencialmente, combinamos todas las tareas
        all_tasks = []
        for bucket in buckets:
            all_tasks.extend(bucket["tasks"])

        # Ejecutar todas las tareas al mismo tiempo
        results = compute(*all_tasks)

        # Actualizar la lista de redes locales con los resultados combinados
        self.l_local_networks = list(results)

        # Procesar señales de acoplamiento para cada red local (paso adicional en el flujo)
        for o_local_network in self.l_local_networks:
            self.process_kind_signal(o_local_network)

        # Paso 2: Asignar índices globales a cada atractor
        self._assign_global_indices_to_attractors()

        # Paso 3: Generar el diccionario de atractores
        self.generate_attractor_dictionary()

        CustomText.make_sub_sub_title("END FIND LOCAL ATTRACTORS WEIGHTED BALANCED")

    def dask_find_compatible_pairs(self) -> None:
        """
        Paraleliza la generación de pares de atractores usando señales de salida.

        Utiliza Dask para calcular pares compatibles y asegura que los resultados
        se integren correctamente a los objetos originales.
        """
        CustomText.make_title("FIND COMPATIBLE ATTRACTOR PAIRS")

        # Función auxiliar para encontrar pares de atractores
        def find_attractor_pairs(
            signal_value, o_output_signal_index_variable, l_attractors_input
        ):
            """
            Encuentra pares de atractores basados en el valor de la señal de entrada.

            Args:
                signal_value (int): El valor de la señal (0 o 1).
                o_output_signal_index_variable: Indice de la variable del objeto de señal de salida.
                l_attractors_input (list): Lista de índices de atractores para la señal de entrada.

            Returns:
                list: Lista de pares de atractores.
            """
            l_attractors_output = [
                o_attractor.g_index
                for o_attractor in self.get_attractors_by_input_signal_value(
                    o_output_signal_index_variable, signal_value
                )
            ]
            return list(itertools.product(l_attractors_input, l_attractors_output))

        # Función auxiliar para procesar una señal de salida
        def process_output_signal(
            signal_index, l_attractors_input_0, l_attractors_input_1, index_variable
        ):
            """
            Procesa una señal de salida y encuentra pares compatibles.

            Args:
                signal_index: Índice de la señal de salida.
                l_attractors_input_0: Lista de atractores para valor 0.
                l_attractors_input_1: Lista de atractores para valor 1.
                index_variable: Variable de índice de la señal.

            Returns:
                dict: Diccionario con los pares de atractores.
            """
            d_comp_pairs_attractors_by_value = {
                0: find_attractor_pairs(0, index_variable, l_attractors_input_0),
                1: find_attractor_pairs(1, index_variable, l_attractors_input_1),
            }

            # Retorna el índice de la señal y el diccionario generado
            n_pairs = len(d_comp_pairs_attractors_by_value[0]) + len(
                d_comp_pairs_attractors_by_value[1]
            )
            return signal_index, d_comp_pairs_attractors_by_value, n_pairs

        # Crear una lista de tareas paralelas
        delayed_tasks = []
        signal_map = {}
        for o_local_network in self.l_local_networks:
            l_output_edges = self.get_output_edges_by_network_index(
                o_local_network.index
            )
            for o_output_signal in l_output_edges:
                signal_index = o_output_signal.index
                signal_map[signal_index] = (
                    o_output_signal  # Mapeo para acceder a los objetos originales
                )
                l_attractors_input_0 = [
                    attr.g_index for attr in o_output_signal.d_out_value_to_attractor[0]
                ]
                l_attractors_input_1 = [
                    attr.g_index for attr in o_output_signal.d_out_value_to_attractor[1]
                ]
                delayed_tasks.append(
                    delayed(process_output_signal)(
                        signal_index,
                        l_attractors_input_0,
                        l_attractors_input_1,
                        o_output_signal.index_variable,
                    )
                )

        # Antes de computar tareas
        logger.info("Tareas creadas: %d", len(delayed_tasks))
        for task in delayed_tasks[:5]:  # Muestra solo las primeras 5
            logger.debug("%s", task)

        # Ejecutar las tareas en paralelo
        results = compute(*delayed_tasks)

        # Después de ejecutar compute
        logger.info("Resultados obtenidos: %d", len(results))
        for result in results[:5]:
            logger.debug("%s", result)

        for idx, result in enumerate(
            results[:5]
        ):  # Mostrar solo los primeros 5 para evitar demasiada información
            logger.debug("Resultado %d: %s", idx, result)

        # Actualizar los objetos originales con los resultados
        n_pairs = 0
        for signal_index, d_comp_pairs_attractors_by_value, n_signal_pairs in results:

            if signal_index not in signal_map:
                logger.error(
                    "Índice de señal %s no encontrado en signal_map", signal_index
                )
                continue  # Saltar este resultado si hay un problema

            o_output_signal = signal_map[signal_index]
            o_output_signal.d_comp_pairs_attractors_by_value = (
                d_comp_pairs_attractors_by_value
            )
            n_pairs += n_signal_pairs

        # Mostrar el resultado final
        # print(f"Number of attractor pairs: {n_pairs}")
        CustomText.make_sub_sub_title("END FIND ATTRACTOR PAIRS")

    # SHOW FUNCTIONS
    def show_directed_edges(self) -> None:
        CustomText.print_duplex_line()
        logger.info("SHOW THE DIRECTED EDGES OF THE CBN")
        for o_directed_edge in self.l_directed_edges:
            o_directed_edge.show()

    def show_directed_edges_order(self) -> None:
        CustomText.print_duplex_line()
        logger.info(
            "SHOW THE EDGES %s",
            " ".join(
                f"{o_directed_edge.index}: {o_directed_edge.get_edge()}"
                for o_directed_edge in self.l_directed_edges
            ),
        )

    def show_coupled_signals_kind(self) -> None:
        CustomText.print_duplex_line()
        logger.info("SHOW THE COUPLED SIGNALS KINDS")
        n_restricted_signals = 0
        for o_directed_edge in self.l_directed_edges:
            logger.info(
                "SIGNAL: %s, RELATION: %s -> %s, KIND: %s - %s",
                o_directed_edge.index_variable,
                o_directed_edge.output_local_network,
                o_directed_edge.input_local_network,
                o_directed_edge.kind_signal,
                o_directed_edge.d_kind_signal[o_directed_edge.kind_signal],
            )
            if o_directed_edge.kind_signal == 1:
                n_restricted_signals += 1
        logger.info("Number of restricted signals: %d", n_restricted_signals)

    def show_description(self) -> None:
        CustomText.make_title("CBN description")
        l_local_networks_indexes = [
            o_local_network.index for o_local_network in self.l_local_networks
        ]
        CustomText.make_sub_title(f"Local Networks: {l_local_networks_indexes}")
        for o_local_network in self.l_local_networks:
            o_local_network.show()
        CustomText.make_sub_title(f"Directed edges: {l_local_networks_indexes}")
        # for o_directed_edge in self.l_directed_edges:
        #     o_directed_edge.show()

    def show_global_scenes(self) -> None:
        CustomText.make_sub_title("LIST OF GLOBAL SCENES")
        for o_global_scene in self.l_global_scenes:
            o_global_scene.show()

    def show_local_attractors(self) -> None:
        CustomText.make_title("Show local attractors")
        for o_local_network in self.l_local_networks:
            CustomText.make_sub_title(f"Network {o_local_network.index}")
            for o_scene in o_local_network.local_scenes:
                title = (
                    f"Network: {o_local_network.index} - Scene: {o_scene.l_values} - "
                    f"N. of Attractors: {len(o_scene.l_attractors)}"
                )
                CustomText.make_sub_sub_title(title)
                logger.info(
                    "Network: %s - Scene: %s", o_local_network.index, o_scene.l_values
                )
                logger.info("Attractors number: %d", len(o_scene.l_attractors))
                for o_attractor in o_scene.l_attractors:
                    CustomText.print_simple_line()
                    logger.info(
                        "Global index: %s -> %s",
                        o_attractor.g_index,
                        self.d_local_attractors[o_attractor.g_index],
                    )
                    for o_state in o_attractor.l_states:
                        logger.debug("%s", o_state.l_variable_values)

    def show_attractor_pairs(self) -> None:
        CustomText.print_duplex_line()
        logger.info("LIST OF THE COMPATIBLE ATTRACTOR PAIRS")

        total_pairs = 0  # Variable to keep track of the total pairs

        for o_directed_edge in self.l_directed_edges:
            CustomText.print_simple_line()
            logger.info(
                "Edge: %s -> %s",
                o_directed_edge.output_local_network,
                o_directed_edge.input_local_network,
            )

            for key in o_directed_edge.d_comp_pairs_attractors_by_value.keys():
                CustomText.print_simple_line()
                logger.info(
                    "Coupling Variable: %s, Scene: %s",
                    o_directed_edge.index_variable,
                    key,
                )

                for o_pair in o_directed_edge.d_comp_pairs_attractors_by_value[key]:
                    logger.debug("%s", o_pair)
                    total_pairs += 1  # Increment total pairs for each pair found
        logger.info("Total compatible attractor pairs: %d", total_pairs)

    def show_stable_attractor_fields(self) -> None:
        CustomText.print_duplex_line()
        logger.info("Show the list of attractor fields")
        logger.info("Number Stable Attractor Fields: %d", len(self.d_attractor_fields))
        for key, o_attractor_field in self.d_attractor_fields.items():
            CustomText.print_simple_line()
            logger.info("%s", key)
            logger.debug("%s", o_attractor_field)

    def show_resume(self) -> None:
        # Method to display a detailed summary of the CBN
        CustomText.make_title("CBN Detailed Resume")

        CustomText.make_sub_sub_title("Main Characteristics")
        CustomText.print_simple_line()
        logger = logging.getLogger(__name__)
        logger.info("Number of local networks: %d", len(self.l_local_networks))
        logger.info(
            "Number of variables per local network: %s", self.get_n_local_variables()
        )
        logger.info("Topology Type: %s", self.get_kind_topology())
        logger.info("Number of input variables: %s", self.get_n_input_variables())
        logger.info("Number of output variables: %s", self.get_n_output_variables())

        CustomText.make_sub_sub_title("Indicators")
        CustomText.print_simple_line()
        logger.info("Number of local attractors: %d", self.get_n_local_attractors())
        logger.info("Number of attractor pairs: %d", self.get_n_pair_attractors())
        logger.info("Number of attractor fields: %d", self.get_n_attractor_fields())
        CustomText.print_simple_line()

    def show_local_attractors_dictionary(self) -> None:
        # Method to display the dictionary of local attractors
        CustomText.make_title("Global Dictionary of Local Attractors")

        for key, value in self.d_local_attractors.items():
            logger.info("%s -> %s", key, value)

    def show_stable_attractor_fields_detailed(self) -> None:
        # Method to display stable attractor fields in detail
        CustomText.print_duplex_line()
        logger.info("Showing the list of attractor fields")
        logger.info(
            "Number of Stable Attractor Fields: %d", len(self.d_attractor_fields)
        )

        for key, value in self.d_attractor_fields.items():
            CustomText.print_simple_line()
            logger.info("%s -> %s", key, value)

            for i_attractor in value:
                logger.info(
                    "%s -> %s", i_attractor, self.d_local_attractors[i_attractor]
                )
                o_attractor = self.get_local_attractor_by_index(i_attractor)

                if o_attractor:
                    o_attractor.show()

    def show_attractor_fields(self) -> None:
        """
        Displays the attractor fields.

        This method prints a list of attractor fields and the total number found.

        Returns:
            None
        """
        CustomText.make_sub_title("List of attractor fields")
        for key, value in self.d_attractor_fields.items():
            logger.info("%s -> %s", key, value)
        logger.info(
            "Number of attractor fields found: %d", len(self.d_attractor_fields)
        )

    # GENERATE FUNCTIONS
    def generate_global_scenes(self) -> None:
        """
        Generates global scenes.

        This method creates all possible binary combinations for the directed edges
        and initializes GlobalScene objects.

        Returns:
            None
        """
        CustomText.make_title("Generated Global Scenes")
        l_edges_indexes = [
            o_directed_edge.index_variable for o_directed_edge in self.l_directed_edges
        ]
        binary_combinations = list(product([0, 1], repeat=len(l_edges_indexes)))
        self.l_global_scenes = [
            GlobalScene(l_edges_indexes, list(combination))
            for combination in binary_combinations
        ]
        CustomText.make_sub_title("Global Scenes generated")

    def plot_topology(self, ax=None) -> None:
        """
        Plots the network topology.

        This method calls the plotting function from the global topology object.

        Args:
            ax (matplotlib.axes._axes.Axes, optional): The axes on which to plot. Defaults to None.

        Returns:
            None
        """
        self.o_global_topology.plot_topology(ax=ax)

    def count_fields_by_global_scenes(self):
        """
        Counts stable attractor fields by global scenes.

        This method creates a dictionary mapping unique scene combinations
        to the number of stable attractor fields associated with them.

        Returns:
            None: The results are stored in `self.d_global_scenes_count`.
        """
        self.d_global_scenes_count: Dict[str, int] = {}

        for key, o_attractor_field in self.d_attractor_fields.items():
            d_variable_value = {}

            for i_attractor in o_attractor_field:
                o_attractor = self.get_local_attractor_by_index(i_attractor)
                if o_attractor:
                    for aux_pos, aux_variable in enumerate(o_attractor.relation_index):
                        d_variable_value[aux_variable] = o_attractor.local_scene[
                            aux_pos
                        ]

            # Generate a sorted key representing the scene combination
            sorted_dict = {k: d_variable_value[k] for k in sorted(d_variable_value)}
            combination_key = "".join(str(sorted_dict[k]) for k in sorted_dict)

            # Update the count of this specific scene combination
            if combination_key in self.d_global_scenes_count:
                self.d_global_scenes_count[combination_key] += 1
            else:
                self.d_global_scenes_count[combination_key] = 1

    # NEW GENERATOR
    @staticmethod
    def cbn_generator(
        v_topology: int,
        n_local_networks: int,
        n_vars_network: int,
        n_input_variables: int,
        n_output_variables: int,
        n_max_of_clauses: Optional[int] = None,
        n_max_of_literals: Optional[int] = None,
        n_edges: Optional[int] = None,
    ) -> "CBN":
        """
        Generates a special CBN based on the provided parameters.

        Args:
            v_topology (str): The topology of the CBN. Can be 'aleatory' or other valid types.
            n_local_networks (int): The number of local networks in the CBN.
            n_vars_network (int): The number of variables per local network.
            n_input_variables (int): The number of input variables in the CBN.
            n_output_variables (int): The number of output variables in the CBN.
            n_max_of_clauses (Optional[int]): The maximum number of clauses for the local networks. Defaults to None.
            n_max_of_literals (Optional[int]): The maximum number of literals for the local networks. Defaults to None.
            n_edges (Optional[int]): The number of edges between local networks. Defaults to None.

        Returns:
            CBN: A CBN instance generated based on the given parameters.
        """

        # GENERATE THE GLOBAL TOPOLOGY
        o_global_topology = GlobalTopology.generate_sample_topology(
            v_topology=v_topology, n_nodes=n_local_networks, n_edges=n_edges
        )

        # GENERATE THE LOCAL NETWORK TEMPLATE
        o_template = LocalNetworkTemplate(
            n_vars_network=n_vars_network,
            n_input_variables=n_input_variables,
            n_output_variables=n_output_variables,
            n_max_of_clauses=n_max_of_clauses,
            n_max_of_literals=n_max_of_literals,
            v_topology=v_topology,
        )

        # GENERATE THE CBN WITH THE TOPOLOGY AND TEMPLATE
        o_cbn = CBN.generate_cbn_from_template(
            v_topology=v_topology,
            n_local_networks=n_local_networks,
            n_vars_network=n_vars_network,
            o_template=o_template,
            l_global_edges=o_global_topology.l_edges,
        )

        return o_cbn

    @staticmethod
    def find_output_edges_by_network_index(
        index: int, l_directed_edges: List["DirectedEdge"]
    ) -> List["DirectedEdge"]:
        """
        Finds all output edges for a given network index.

        Args:
            index (int): The index of the local network.
            l_directed_edges (List[DirectedEdge]): List of DirectedEdge objects.

        Returns:
            List[DirectedEdge]: List of DirectedEdge objects that are output edges for the specified network index.
        """
        return [edge for edge in l_directed_edges if edge.output_local_network == index]

    @staticmethod
    def find_input_edges_by_network_index(index, l_directed_edges):
        """
        Finds all input edges for a given network index.

        Args:
            index (int): The index of the local network.
            l_directed_edges (list): List of DirectedEdge objects.

        Returns:
            list: List of DirectedEdge objects that are input edges for the specified network index.
        """
        return [edge for edge in l_directed_edges if edge.input_local_network == index]

    @staticmethod
    def generate_local_networks_indexes_variables(n_local_networks, n_vars_network):
        """
        Generates local networks and their variable indexes.

        Args:
            n_local_networks (int): Number of local networks to generate.
            n_vars_network (int): Number of variables per network.

        Returns:
            list: List of LocalNetwork objects.
        """
        l_local_networks = []
        v_cont_var = 1
        for v_num_network in range(1, n_local_networks + 1):
            # generate the variables of the networks
            internal_variables = list(range(v_cont_var, v_cont_var + n_vars_network))
            # create the Local Network object
            o_local_network = LocalNetwork(index=v_num_network, internal_variables=internal_variables)
            # add the local network object to the list
            l_local_networks.append(o_local_network)
            # update the index of the variables
            v_cont_var += n_vars_network
        return l_local_networks

    @staticmethod
    def generate_cbn_from_template(
        v_topology, n_local_networks, n_vars_network, o_template, l_global_edges
    ):
        """
        Generates a CBN (Coupled Boolean Network) using a given template and global edges.

        Args:
            v_topology: Topology of the CBN.
            n_local_networks (int): Number of local networks.
            n_vars_network (int): Number of variables per network.
            o_template: Template for local networks.
            l_global_edges (list): List of tuples representing the global edges between local networks.

        Returns:
            A CBN object generated from the provided template and global edges.
        """

        # Generate the local networks with indexes and variables (without relations or dynamics)
        l_local_networks = CBN.generate_local_networks_indexes_variables(
            n_local_networks=n_local_networks, n_vars_network=n_vars_network
        )

        # Generate the directed edges between the local networks
        l_directed_edges = []

        # Get the last index of the variables for the indexes of the directed edges
        i_last_variable = l_local_networks[-1].internal_variables[-1] + 1

        # Generate the directed edges using the last variable generated and the selected output variables
        i_directed_edge = 1
        for relation in l_global_edges:
            output_local_network = relation[0]
            input_local_network = relation[1]

            # Get the output variables from the template
            l_output_variables = o_template.get_output_variables_from_template(
                output_local_network, l_local_networks
            )

            # Generate the coupling function
            coupling_function = (
                " " + " ∨ ".join(list(map(str, l_output_variables))) + " "
            )
            # Create the DirectedEdge object
            o_directed_edge = DirectedEdge(
                index=i_directed_edge,
                index_variable_signal=i_last_variable,
                input_local_network=input_local_network,
                output_local_network=output_local_network,
                l_output_variables=l_output_variables,
                coupling_function=coupling_function,
            )
            i_last_variable += 1
            i_directed_edge += 1
            # Add the DirectedEdge object to the list
            l_directed_edges.append(o_directed_edge)

        # Process the coupling signals for every local network
        for o_local_network in l_local_networks:
            # Find the input signals for each local network
            input_signals = CBN.find_input_edges_by_network_index(
                index=o_local_network.index, l_directed_edges=l_directed_edges
            )
            # Process the input signals of the local network
            o_local_network.process_input_signals(input_signals=input_signals)

        # Generate the dynamics of the local networks using the template
        l_local_networks = CBN.generate_local_dynamic_with_template(
            o_template=o_template,
            l_local_networks=l_local_networks,
            l_directed_edges=l_directed_edges,
        )

        # Generate the special Coupled Boolean Network (CBN)
        o_cbn = CBN(
            l_local_networks=l_local_networks, l_directed_edges=l_directed_edges
        )

        # Add the Global Topology Object
        o_global_topology = GlobalTopology(
            v_topology=v_topology, l_edges=l_global_edges
        )
        o_cbn.o_global_topology = o_global_topology

        return o_cbn

    @staticmethod
    def generate_local_dynamic_with_template(
        o_template, l_local_networks, l_directed_edges
    ):
        """
        Generates the dynamics for each local network using a given template and directed edges.

        Args:
            o_template: Template used to generate dynamics.
            l_local_networks (list): List of LocalNetwork objects to update.
            l_directed_edges (list): List of DirectedEdge objects for the connections between networks.

        Returns:
            list: Updated list of LocalNetwork objects with their dynamics.
        """
        # number_max_of_clauses and number_max_of_literals are intentionally
        # omitted because they are not used in this implementation.

        # List to store the updated local networks
        l_local_networks_updated = []

        # Update the dynamics for each local network
        for o_local_network in l_local_networks:
            # CustomText.print_simple_line()
            # print("Local Network:", o_local_network.index)

            # List to hold the function descriptions for the variables
            descriptive_function_variables = []

            # Generate clauses for each local network based on the template
            for i_local_variable in o_local_network.internal_variables:
                CustomText.print_simple_line()
                # Adapt the clause template to the 5_specific variable
                l_clauses_node = CBN.update_clause_from_template(
                    o_template=o_template,
                    l_local_networks=l_local_networks,
                    o_local_network=o_local_network,
                    i_local_variable=i_local_variable,
                    l_directed_edges=l_directed_edges,
                )

                # Create an InternalVariable object with the generated clauses
                o_variable_model = InternalVariable(
                    index=i_local_variable, cnf_function=l_clauses_node
                )
                # Add the variable model to the list
                descriptive_function_variables.append(o_variable_model)

            # Update the local network with the function descriptions
            o_local_network.descriptive_function_variables = descriptive_function_variables.copy()
            l_local_networks_updated.append(o_local_network)
            # print("Local network created:", o_local_network.index)
            # CustomText.print_simple_line()

        # Return the updated list of local networks
        return l_local_networks_updated

    @staticmethod
    def update_clause_from_template(
        o_template,
        l_local_networks,
        o_local_network,
        i_local_variable,
        l_directed_edges,
    ):
        """
        Updates the clauses from the template for a 5_specific variable in a local network.

        Args:
            o_template: The template containing CNF functions.
            l_local_networks (list): List of LocalNetwork objects.
            o_local_network: The 5_specific LocalNetwork object being updated.
            i_local_variable: The index of the local variable to update.
            l_directed_edges (list): List of DirectedEdge objects.

        Returns:
            list: Updated list of clauses for the local variable.
        """

        # Gather all index variables from directed edges
        # l_indexes_directed_edges was previously computed but not used.

        # Determine the CNF function index for the variable in the template
        n_local_variables = len(l_local_networks[0].internal_variables)
        i_template_variable = (
            i_local_variable
            - ((o_local_network.index - 1) * n_local_variables)
            + n_local_variables
        )
        pre_l_clauses_node = o_template.d_variable_cnf_function[i_template_variable]

        # print("Local Variable index:", i_local_variable)
        # print("Template Variable index:", i_template_variable)
        # print("Template Function:", pre_l_clauses_node)

        # Update the CNF function clauses with the 5_specific variable index
        l_clauses_node = []
        for pre_clause in pre_l_clauses_node:
            # Create a clause by updating variable indices
            l_clause = []
            for template_value in pre_clause:
                # Determine the sign of the variable
                b_symbol = True
                if template_value < 0:
                    b_symbol = False

                # Update the variable index
                local_value = (
                    abs(template_value)
                    + ((o_local_network.index - 3) * n_local_variables)
                    + n_local_variables
                )

                # Check if the variable is internal or external
                if local_value not in o_local_network.internal_variables:
                    # Use external variables if the local variable is not found
                    l_clause = o_local_network.external_variables
                    break

                # Add the sign to the value
                if not b_symbol:
                    local_value = -local_value

                # Append the value to the clause
                l_clause.append(local_value)

            # Append the updated clause to the list
            l_clauses_node.append(l_clause)

        # Remove empty clauses
        l_clauses_node = [clause for clause in l_clauses_node if clause]

        # print("Local Variable Index:", i_local_variable)
        # print("CNF Function:", l_clauses_node)

        return l_clauses_node

    # GETTERS FUNCTIONS
    def get_local_attractor_by_index(
        self, i_attractor: int
    ) -> Optional[LocalAttractor]:
        """
        Method to retrieve a local attractor by its index.

        Args:
            i_attractor (int): The index of the attractor to find.

        Returns:
            Optional[LocalAttractor]: The corresponding attractor if found, otherwise None.
        """
        for o_local_network in self.l_local_networks:
            for o_scene in o_local_network.local_scenes:
                for o_attractor in o_scene.l_attractors:
                    if o_attractor.g_index == i_attractor:
                        return o_attractor
        logger.error("Attractor index not found: %s", i_attractor)
        return None

    def get_kind_topology(self):
        return self.o_global_topology.v_topology

    def get_n_input_variables(self):
        pass

    def get_n_output_variables(self):
        pass

    def get_network_by_index(self, index: int) -> Optional[LocalNetwork]:
        for o_local_network in self.l_local_networks:
            if o_local_network.index == index:
                return o_local_network
        return None

    def get_input_edges_by_network_index(self, index: int) -> List[DirectedEdge]:
        return [
            o_directed_edge
            for o_directed_edge in self.l_directed_edges
            if o_directed_edge.input_local_network == index
        ]

    def get_output_edges_by_network_index(self, index: int) -> List[DirectedEdge]:
        return [
            o_directed_edge
            for o_directed_edge in self.l_directed_edges
            if o_directed_edge.output_local_network == index
        ]

    def get_index_networks(self) -> List[int]:
        return [i_network.l_index for i_network in self.l_local_networks]

    def get_attractors_by_input_signal_value(
        self, index_variable_signal: int, signal_value: int
    ) -> List[LocalAttractor]:
        l_attractors = []
        for o_local_network in self.l_local_networks:
            for scene in o_local_network.local_scenes:
                if (
                    scene.l_values is not None
                    and index_variable_signal in scene.l_index_signals
                ):
                    pos = scene.l_index_signals.index(index_variable_signal)
                    if scene.l_values[pos] == str(signal_value):
                        l_attractors.extend(scene.l_attractors)
        return l_attractors

    def get_n_local_attractors(self) -> int:
        return sum(
            len(o_scene.l_attractors)
            for o_local_network in self.l_local_networks
            for o_scene in o_local_network.local_scenes
        )

    def get_n_pair_attractors(self) -> int:
        return sum(
            len(o_directed_edge.d_comp_pairs_attractors_by_value[0])
            + len(o_directed_edge.d_comp_pairs_attractors_by_value[1])
            for o_directed_edge in self.l_directed_edges
        )

    def get_n_attractor_fields(self) -> int:
        return len(self.d_attractor_fields)

    def get_n_local_variables(self) -> int:
        return (
            len(self.l_local_networks[0].internal_variables) if self.l_local_networks else 0
        )

    def get_global_scene_attractor_fields(self):
        return self.d_global_scenes_count


# Backwards-compatible assignments: expose utility functions as CBN staticmethods
CBN.evaluate_pair = staticmethod(_evaluate_pair)
CBN.cartesian_product_mod = staticmethod(_cartesian_product_mod)
CBN.flatten = staticmethod(_flatten)
CBN._convert_to_tuple = staticmethod(_convert_to_tuple)
CBN.process_single_base_pair = staticmethod(_process_single_base_pair)
# Backwards-compatible alias for legacy method name
if not hasattr(CBN, 'show_attractors_fields'):
    CBN.show_attractors_fields = CBN.show_attractor_fields
